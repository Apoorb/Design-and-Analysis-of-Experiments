DatFromWsu <- read.table("DataWsu.csv.zip", nrows=10, header=T, quote="\"", sep=",")
rm(list=ls())
dir1='C:/Users/a-bibeka/Syncplicity Folders/SD_AB_Collaborations (Subasish Das)/Dissertation/Dataset/SPMD'
dir2='/Users/Apoorb/Syncplicity Folders/SD_AB_Collaborations/Dissertation/Dataset/SPMD'
dir=dir1
knitr::opts_chunk$set(echo = TRUE,root.dir=dir)
rm(list=ls())
dir1='C:/Users/a-bibeka/Syncplicity Folders/SD_AB_Collaborations (Subasish Das)/Dissertation/Dataset/SPMD'
dir2='/Users/Apoorb/Syncplicity Folders/SD_AB_Collaborations/Dissertation/Dataset/SPMD'
dir=dir1
knitr::opts_chunk$set(echo = TRUE,root.dir=dir)
getwd()
DatFromWsu <- read.table("DataWsu.csv.zip", nrows=10, header=T, quote="\"", sep=",")
rm(list=ls())
dir1='C:/Users/a-bibeka/Syncplicity Folders/SD_AB_Collaborations (Subasish Das)/Dissertation/Dataset/SPMD'
dir2='/Users/Apoorb/Syncplicity Folders/SD_AB_Collaborations/Dissertation/Dataset/SPMD'
dir=dir1
knitr::opts_chunk$set(echo = TRUE,root.dir=dir)
getwd()
require(data.table)
require(ggplot2)
NrCrsh<-fread("NearCrashes.csv")
NrCrsh<-fread("NearCrashes.csv")
# f1="DataFrontTargets.csv"
# DatFromTarget<-fread(f1,header=TRUE)
# DatFromTarget<-na.omit(DatFromTarget)
# summary(DatFromTarget)
# head(DatFromTarget,10)
# length(unique(DatFromTarget$Device))  #94 unique vehicles
# Dat1<-DatFromTarget[CIPV==1 & Status==3,]
# fwrite(Dat1,file="DatFromTarget_Carfollowing.csv")
NrCrsh<-fread("NearCrashes.csv")
f2<-paste(dir,"/NearCrashes.csv")
NrCrsh<-fread(f2)
f2<-paste(dir,"/NearCrashes.csv")
f2
f2<-paste(dir,"/NearCrashes.csv",sep = "")
NrCrsh<-fread(f2)
View(NrCrsh)
hist(NrCrsh$AxWsu,"Acceleration m/s2")
NrCrsh$AxWsu,
NrCrsh$AxWsu
hist(NrCrsh$AxWsu,main = "Acceleration m/s2")
colnames(NrCrsh)
NrCrsh[,SpdMph:=2.23694*GpsSpeedWsu]
NrCrsh1<-NrCrsh1[,SpdMph>=25]
NrCrsh1<-NrCrsh[,SpdMph>=25]
NrCrsh1
NrCrsh1<-NrCrsh[,SpdMph>=25,]
NrCrsh1
NrCrsh1<-NrCrsh[,SpdMph>=25,.()]
View(NrCrsh1)
?subset
NrCrsh1<-subset(NrCrsh,SpdMph>=25)
View(NrCrsh1)
da2<-NrCrsh1$Device
N1<-as.data.table(table(NrCrsh1$Device))
View(N1)
View(N1)
View(N1)
f2<-paste(dir,"/NearCrashes.csv",sep = "")
NrCrsh<-fread(f2)
hist(NrCrsh$AxWsu,main = "Acceleration m/s2")
NrCrsh[,SpdMph:=2.23694*GpsSpeedWsu]
NrCrsh1<-subset(NrCrsh,SpdMph>=25)
N1<-as.data.table(table(NrCrsh1$Device))
colnames(N1)<-c("Device","NearCrashes")
N1[,plot(Device,NearCrashes,main="No of Near Crashes Per Vehicle (70 vehicles out of 94)")]
rm(list=ls())
dir1='C:/Users/a-bibeka/Syncplicity Folders/SD_AB_Collaborations (Subasish Das)/Dissertation/Dataset/SPMD'
dir2='/Users/Apoorb/Syncplicity Folders/SD_AB_Collaborations/Dissertation/Dataset/SPMD'
dir=dir1
knitr::opts_chunk$set(echo = TRUE,root.dir=dir)
getwd()
require(data.table)
require(ggplot2)
# f1="DataFrontTargets.csv"
# DatFromTarget<-fread(f1,header=TRUE)
# DatFromTarget<-na.omit(DatFromTarget)
# summary(DatFromTarget)
# head(DatFromTarget,10)
# length(unique(DatFromTarget$Device))  #94 unique vehicles
# Dat1<-DatFromTarget[CIPV==1 & Status==3,]
# fwrite(Dat1,file="DatFromTarget_Carfollowing.csv")
?setorderv
require(data.table)
?setorderv
rm(list=ls())
#dir1="/Users/Apoorb/Syncplicity Folders/SD_AB_Collaborations/Potential Topics/TRB2019--FRS_SD/AB/Paper_CV_2/Processed Data"
#dir1="C:/Users/a-bibeka/Syncplicity Folders/SD_AB_Collaborations (Subasish Das)/Potential Topics/TRB2019--FRS_SD/AB/Paper_CV_2/Processed Data"
knitr::opts_knit$set(echo=TRUE,root.dir="../Processed Data")
#setwd("../Processed Data")
getwd()
getwd()
source("../Analysis/Helper.R")
require(data.table)
require(ggplot2)
getwd()
datWSU10<-fread("DatWsu10Cars.csv")
datFrn10<-fread("DatFrontTar10Cars.csv")
#datLn10<-fread("DatLane10Cars.csv")
# Get time of the trip
datWSU10[,dt:=as.POSIXct(GpsTimeWsu/1000, origin="1970-01-01")]
datcm10<-merge(datFrn10,datWSU10,by=c("Device","Trip","Time"))
sum(is.na(datcm10))
# Data summary
#summary(datcm10)
datRe<-datcm10[,.(Device,Trip,Time,TargetId,TargetType,ObstacleId,Range,Rangerate,Transversal,Status,CIPV,GpsValidWsu,GpsTimeWsu,LatitudeWsu,LongitudeWsu,GpsHeadingWsu,GpsSpeedWsu,YawRateWsu,SpeedWsu,BrakeAbsTcsWsu,AxWsu,dt)]
datcm10<-NULL
str(datRe)
setkey(datRe,Device,Trip,Time)
setkey(datWSU10,Device,Trip,Time)
datFreqTm<-datWSU10[,.(Device,Trip,Time)] #WSU should record throught out the trip but radar will only record when a leader or nearby vehicle is present
datFreqTm[,Fq:=c(NA,diff(Time)),by=list(Device,Trip)]
datFreqTm<-na.omit(datFreqTm)
datFreqTm[,Fq:=Fq/100]
hist(datFreqTm$Fq)
quantile(datFreqTm$Fq,.9999) #Seconds
quantile(datFreqTm$Fq,.99999) #Seconds
summary(datFreqTm$Fq)  # summary in seconds
# % of the data lost
#**************************************
fln<-nrow(datRe)
ln<-max(nrow(datFrn10),nrow(datWSU10))
Perdatlost<-(ln-fln)*100/ln
# % of data lost =
Perdatlost
# Unique trips in WSU data
trpWsu<-unique(datWSU10$Trip)
# Unique trips in Front Target data data
trpFrn<-unique(datFrn10$Trip)
setdiff(trpWsu,trpFrn)
# This implies that there are trips where WSU was recording data but Radar was not
# Rename Devices
len=length(unique(datRe$Device))
da1=data.table(A=seq(len),Device=unique(datRe$Device))
datRe$Dv<-da1$A[match(datRe$Device,da1$Device)]
datRe[,SpdMph:=GpsSpeedWsu*2.23694]
datRe[,Dv:=as.numeric(Dv)]
# Results about data collection period
#
TT<-datRe[,.(MinT=min(Time),MaxT=max(Time)),by=list(Device,Trip)]
temp<-unique(datRe[,.(Device,Dv)])
TT<-merge(TT,temp,by="Device")
TT$`TripDur (min)`=round((TT$MaxT-TT$MinT)/(60*100),digits=2)
TT1<-TT[`TripDur (min)`>10,]
TT2<-TT1[,.(TripDurMin=sum(`TripDur (min)`),Device=min(Device)),by=Dv,]
fwrite(TT2,"TripDur.csv")
datRe<-merge(datRe,TT1[,.(Device,Trip,`TripDur (min)`)],by=c("Device","Trip"))
#
datRe1<-datRe[CIPV==1,]
datRe1<-datRe1[Range>0]
# Prelim Graphs
#****************************************
#Speeding
hist(datRe$SpdMph)
datRe[,abline(v=75,col="Blue",lwd=2)]
sum(datRe$SpdMph>75)*100/nrow(datRe)
re=list()
re[[1]]=ggplot(datRe,aes(x=Dv,y=SpdMph,group=as.factor(Dv)))+geom_boxplot(fill="blue",alpha=0.4)+theme_bw()+xlab("Device")+ylab("Speed (Mph)")+scale_x_continuous(breaks =seq(min(datRe$Dv), max(datRe$Dv), by =1))
daSpeed<-datRe[SpdMph>75,]
re[[2]]=ggplot(daSpeed,aes(x=Dv,y=SpdMph,group=as.factor(Dv)))+geom_boxplot(fill="blue",alpha=0.4)+theme_bw()+xlab("Device")+ylab("Speed\n(speed > 75 mph)")+scale_x_continuous(breaks =seq(min(datRe$Dv), max(datRe$Dv), by =1))
TotTT<-as.data.table(table(datRe$Dv))
TmSpd<-as.data.table(table(daSpeed$Dv))
colnames(TotTT)<-c("Dv","TotTT")
colnames(TmSpd)<-c("Dv","TmSpd")
TmSpd<-merge(TotTT,TmSpd,all.x=TRUE)
TmSpd[is.na(TmSpd),TmSpd:=0]
TmSpd[,perSpd:=round(TmSpd*100/TotTT,2)]
TmSpd[,Dv:=as.numeric(Dv)]
re[[3]]=ggplot(TmSpd,aes(x=Dv,y=perSpd,fill=as.factor(Dv)))+geom_bar(stat="identity")+theme_bw()+guides(fill=FALSE)+xlab("Device")+ylab("% speeding\n(speed > 75 mph)")+scale_x_continuous(breaks =seq(min(datRe$Dv), max(datRe$Dv), by =1))
#Tailgaiting
datRe1[,tgap:=Range/GpsSpeedWsu]
# Can vehicle longitudinal jerk be used to identify aggressive drivers
# 0.4 sec time gap is the 99th percentile value for the above paper
# We can do the smae exercise
re1<-PerT(dat=datRe1,var="tgap",Th1=0.4,Th2=5,ylab1_="Time gap (sec)",ylab2_ = "% of time tailgaiting")
datRe1[Rangerate==0,Rangerate:=0.01]
datRe1[,ttc:=Range/Rangerate]
datRe1[ttc<=0,ttc:=9999]
summary(datRe1$ttc)
# Don't Use an Upper threshold for ttc
re2<-PerT(dat=datRe1,var="ttc",Th1=1.5,Th2=100,ylab1_="TTC (sec)",ylab2_ = "% of time ttc<1.5 ")
# re2[[1]]
# re2[[2]]
# re2[[3]]
pdf("../Figures/PrelimPlots.pdf")
multiplot(re1[[1]],re1[[2]],re1[[3]],cols=1)
multiplot(re2[[1]],re2[[2]],re2[[3]],cols=1)
multiplot(re[[1]],re[[2]],re[[3]],cols=1)
graphics.off()
TT2
re1[[4]]
re2[[4]]
#TT2<-merge(TT2)
multiplot(re1[[1]],re1[[2]],re1[[3]],cols=1)
multiplot(re2[[1]],re2[[2]],re2[[3]],cols=1)
multiplot(re[[1]],re[[2]],re[[3]],cols=1)
TT2
re1[[4]]
re1[[4]]<-re1[[4]][,.(Dv,per)]
setname(re1[[4]],"per","PerTimeTailGait")
re1[[4]]<-re1[[4]][,.(Dv,per)]
setnames(re1[[4]],"per","PerTimeTailGait")
re2[[4]]<-re2[[4]][,.(Dv,per)]
setnames(re2[[4]],"per","PerTimeTTles1_5")
TT2<-merge(TT2,re1[[4]],re2[[4]])
re1[[4]]
re2[[4]]
TT2<-merge(TT2,re1[[4]])
TT2<-merge(TT2,re2[[4]])
TT2
TmSpd
TmSpd<-TmSpd[,.(Dv,perSpd)]
TT2<-merge(TT2,TmSpd)
TT2
fwrite(TT2,"TripDur.csv")
datRe[,.(mean=mean(SpdMph),sd=sd(age)),by=Dv]
datRe[,.(mean=mean(SpdMph),sd=sd(SpdMph)),by=Dv]
datRe[,.(summary(SpdMph)),by=Dv]
datReSum <- datRe[,list(range1=range(SpdMph),
mean=mean(SpdMph),
min=min(SpdMph),
lower=quantile(SpdMph, .25, na.rm=TRUE),
middle=quantile(SpdMph, .50, na.rm=TRUE),
upper=quantile(SpdMph, .75, na.rm=TRUE),
max=max(SpdMph)),
by='Dv']
datReSum
datReSum <- datRe[,list(range1=range(SpdMph),
mean=mean(SpdMph),
min=min(SpdMph),
lower=quantile(SpdMph, .25, na.rm=TRUE),
middle=quantile(SpdMph, .50, na.rm=TRUE),
upper=quantile(SpdMph, .75, na.rm=TRUE),
max=max(SpdMph)),
by=Dv]
datReSum
summary(datRe$Device)
summary(datRe$Dv)
str(datRe$Dv)
datRe[,.(range1=range(SpdMph),
mean=mean(SpdMph),
min=min(SpdMph),
lower=quantile(SpdMph, .25, na.rm=TRUE),
middle=quantile(SpdMph, .50, na.rm=TRUE),
upper=quantile(SpdMph, .75, na.rm=TRUE),
max=max(SpdMph)),
by=Dv]
datRe[,.(range1=range(SpdMph),
mean=mean(SpdMph),
min=min(SpdMph),
max=max(SpdMph)),
by=Dv]
datRe[,mean(SpdMph),by=Dv]
datRe[,range(SpdMph),by=Dv]
datReSum <- datRe[,.(
mean=mean(SpdMph),
sd=sd(SpdMph)
min=min(SpdMph),
?sd
datReSum <- datRe[,.(
mean=mean(SpdMph),
sd=sd(SpdMph),
min=min(SpdMph),
lower=quantile(SpdMph, .25, na.rm=TRUE),
middle=quantile(SpdMph, .50, na.rm=TRUE),
upper=quantile(SpdMph, .75, na.rm=TRUE),
max=max(SpdMph)),
by=Dv]
datReSum
str(datRe)
Sdat<-datRe[,.(Dv,round(SpdMph,digits=2))]
datReSum <- Sdat[,.(
mean=mean(SpdMph),
sd=sd(SpdMph),
min=min(SpdMph),
lower=quantile(SpdMph, .25, na.rm=TRUE),
middle=quantile(SpdMph, .50, na.rm=TRUE),
upper=quantile(SpdMph, .75, na.rm=TRUE),
max=max(SpdMph)),
by=Dv]
head(Sdat)
Sdat<-datRe[,.(Dv=Dv,SpdMph=round(SpdMph,digits=2))]
datReSum <- Sdat[,.(
mean=mean(SpdMph),
sd=sd(SpdMph),
min=min(SpdMph),
lower=quantile(SpdMph, .25, na.rm=TRUE),
middle=quantile(SpdMph, .50, na.rm=TRUE),
upper=quantile(SpdMph, .75, na.rm=TRUE),
max=max(SpdMph)),
by=Dv]
datReSum
datReSum <-datRe[,.(
meanSpd=mean(SpdMph),
sdSpd=sd(SpdMph),
minSpd=min(SpdMph),
lowerSpd=quantile(SpdMph, .25, na.rm=TRUE),
middleSpd=quantile(SpdMph, .50, na.rm=TRUE),
upperSpd=quantile(SpdMph, .75, na.rm=TRUE),
maxSpd=max(SpdMph)),
by=Dv]
datReSum
str(datRe1)
datReSum1 <-datRe1[,.(meanTgap=mean(tgap),sdTgap=sd(tgap),mintgap=min(tgap),lowerTgap=quantile(tgap, .25, na.rm=TRUE), middleTgap=quantile(tgap, .50, na.rm=TRUE),upperTgap=quantile(tgap, .75, na.rm=TRUE),maxTgap=max(tgap)),by=Dv]
datReSum1
datReSum1 <-datRe1[Range>0,.(meanTgap=mean(tgap),sdTgap=sd(tgap),mintgap=min(tgap),lowerTgap=quantile(tgap, .25, na.rm=TRUE), middleTgap=quantile(tgap, .50, na.rm=TRUE),upperTgap=quantile(tgap, .75, na.rm=TRUE),maxTgap=max(tgap)),by=Dv]
datReSum1
datRe1[tgap==NaN]
datRe1[is.na(tgap),]
datRe1<-datRe1[Range>0 & SpeedWsu>0,]
datReSum1 <-datRe1[,.(meanTgap=mean(tgap),sdTgap=sd(tgap),mintgap=min(tgap),lowerTgap=quantile(tgap, .25, na.rm=TRUE), middleTgap=quantile(tgap, .50, na.rm=TRUE),upperTgap=quantile(tgap, .75, na.rm=TRUE),maxTgap=max(tgap)),by=Dv]
datReSum1
datReSum2<-datRe1[,.(meanTTC=mean(ttc),sdTTC=sd(ttc),minTTC=min(ttc),lowerTTC=quantile(ttc, .25, na.rm=TRUE), middleTTC=quantile(ttc, .50, na.rm=TRUE),upperTTC=quantile(ttc, .75, na.rm=TRUE),maxTTC=max(ttc)),by=Dv]
datReSum2
datReSum<-merge(datReSum,datReSum1)
datReSum<-merge(datReSum,datReSum2)
datReSum
datReSum <-datRe[,.(meanSpd=round(mean(SpdMph),2),sdSpd=round(sd(SpdMph),2),minSpd=round(min(SpdMph),2),lowerSpd=round(quantile(SpdMph, .25, na.rm=TRUE),2), middleSpd=round(quantile(SpdMph, .50, na.rm=TRUE),2),round(upperSpd=quantile(SpdMph, .75, na.rm=TRUE),2),maxSpd=round(max(SpdMph),2)),by=Dv]
datReSum <-datRe[,.(meanSpd=round(mean(SpdMph),2),sdSpd=round(sd(SpdMph),2),minSpd=round(min(SpdMph),2),lowerSpd=round(quantile(SpdMph, .25, na.rm=TRUE),2), middleSpd=round(quantile(SpdMph, .50, na.rm=TRUE),2),upperSpd=round(quantile(SpdMph, .75, na.rm=TRUE),2),maxSpd=round(max(SpdMph),2)),by=Dv]
datReSum
datReSum1 <-datRe1[,.(meanTgap=round(mean(tgap),2),sdTgap=round(sd(tgap),2),mintgap=round(min(tgap),2),lowerTgap=round(quantile(tgap, .25, na.rm=TRUE),2), middleTgap=round(quantile(tgap, .50, na.rm=TRUE),2),upperTgap=round(quantile(tgap, .75, na.rm=TRUE),2),maxTgap=round(max(tgap),2)),by=Dv]
datReSum1
datReSum2<-datRe1[,.(meanTTC=round(mean(ttc),2),sdTTC=round(sd(ttc),2),minTTC=round(min(ttc),2),lowerTTC=round(quantile(ttc, .25, na.rm=TRUE),2), middleTTC=round(quantile(ttc, .50, na.rm=TRUE),2),upperTTC=round(quantile(ttc, .75, na.rm=TRUE),2),maxTTC=round(max(ttc),2)),by=Dv]
datReSum2
TT2
datReSum<-merge(TT2,datReSum)
fwrite(datReSum,"SumStat.csv")
datReSum <-datRe[,.(meanSpd=round(mean(SpdMph),2),sdSpd=round(sd(SpdMph),2),minSpd=round(min(SpdMph),2),lowerSpd=round(quantile(SpdMph, .25, na.rm=TRUE),2), middleSpd=round(quantile(SpdMph, .50, na.rm=TRUE),2),upperSpd=round(quantile(SpdMph, .75, na.rm=TRUE),2),maxSpd=round(max(SpdMph),2)),by=Dv]
datReSum1 <-datRe1[,.(meanTgap=round(mean(tgap),2),sdTgap=round(sd(tgap),2),mintgap=round(min(tgap),2),lowerTgap=round(quantile(tgap, .25, na.rm=TRUE),2), middleTgap=round(quantile(tgap, .50, na.rm=TRUE),2),upperTgap=round(quantile(tgap, .75, na.rm=TRUE),2),maxTgap=round(max(tgap),2)),by=Dv]
datReSum2<-datRe1[,.(meanTTC=round(mean(ttc),2),sdTTC=round(sd(ttc),2),minTTC=round(min(ttc),2),lowerTTC=round(quantile(ttc, .25, na.rm=TRUE),2), middleTTC=round(quantile(ttc, .50, na.rm=TRUE),2),upperTTC=round(quantile(ttc, .75, na.rm=TRUE),2),maxTTC=round(max(ttc),2)),by=Dv]
datReSum<-merge(datReSum,datReSum1)
datReSum<-merge(datReSum,datReSum2)
datReSum<-merge(TT2,datReSum)
fwrite(datReSum,"SumStat.csv")
rm(list=ls())
#dir1="/Users/Apoorb/Syncplicity Folders/SD_AB_Collaborations/Potential Topics/TRB2019--FRS_SD/AB/Paper_CV_2/Processed Data"
#dir1="C:/Users/a-bibeka/Syncplicity Folders/SD_AB_Collaborations (Subasish Das)/Potential Topics/TRB2019--FRS_SD/AB/Paper_CV_2/Processed Data"
knitr::opts_knit$set(echo=TRUE,root.dir="../Processed Data/10Cars")
#setwd("../Processed Data")
getwd()
getwd()
source("../../Analysis/Helper.R")
require(data.table)
require(ggplot2)
?merge
(dt1 <- data.table(A = letters[1:10], X = 1:10, key = "A"))
(dt2 <- data.table(A = letters[5:14], Y = 1:10, key = "A"))
merge(dt1, dt2)
dt1
dt2
?dnorm
1-dnorm(4,0,1)
1-dnorm(4,0,1)+dnorm(-4)
dnorm(-4)
dnorm(4,0,2)
dnorm(4,0,1)
1-pnorm(4,0,1)+pnorm(-4)
(10^6)*(1-pnorm(4,0,1)+pnorm(-4))
(10^6)*(1-pnorm(4-1,0,1)+pnorm(-4-1))
?pt
qt(0.975,2)
Y=dat$Y
X=dat
X$Y=NULL
rm(list=ls())
library(data.table)
setwd("C:\\Users\\a-bibeka\\Documents\\GitHub\\Python-Code-Compilation")
dat<- fread("Q9Dat.csv")
fit<-aov(Y~factor(A)+factor(B)+factor(C)+factor(D)+factor(E)+factor(F)+factor(A):factor(C)+factor(A):factor(E),data=dat)
res=summary(fit)
fwrite(res,"anovaQ9.csv")
#***************************************************
#Subset Regression
dat<-fread("DesDatQ9.csv")
dat$V1=NULL
library(leaps)
#regsubsets is used for gettting a subset model that is best
Y=dat$Y
X=dat
X$Y=NULL
regfit.full=regsubsets(X,Y)
reg.summary=summary(regfit.full)
#
par(mfrow=c(2,2))
#Choosing RSS for best model for each p
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
#Choosing the adjusted R2 for best model for each p
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
#Value of p (predictor) for which the R2 is maximum
a0=which.max(reg.summary$adjr2)
points(a0,reg.summary$adjr2[a0], col="red",cex=2,pch=20)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
b0=which.min(reg.summary$cp)
points(b0,reg.summary$cp[b0],col="red",cex=2,pch=20)
c0=which.min(reg.summary$bic)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(c0,reg.summary$bic[c0],col="red",cex=2,pch=20)
coef(regfit.full,5)
b0
c0
a0
coef(regfit.full,c0)
View(dat)
View(dat)
rm(list=ls())
library(data.table)
setwd("C:\\Users\\a-bibeka\\Documents\\GitHub\\Python-Code-Compilation")
dat<- fread("Q9Dat.csv")
fit<-aov(Y~factor(A)+factor(B)+factor(C)+factor(D)+factor(E)+factor(F)+factor(A):factor(C)+factor(A):factor(E),data=dat)
res=summary(fit)
fwrite(res,"anovaQ9.csv")
#***************************************************
#Subset Regression
dat<-fread("DesDatQ9.csv")
dat$V1=NULL
library(leaps)
#regsubsets is used for gettting a subset model that is best
Y=dat$Y
X=dat
X$Y=NULL
regfit.full=regsubsets(X,Y)
reg.summary=summary(regfit.full)
#
par(mfrow=c(2,2))
#Choosing RSS for best model for each p
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
#Choosing the adjusted R2 for best model for each p
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
#Value of p (predictor) for which the R2 is maximum
a0=which.max(reg.summary$adjr2)
points(a0,reg.summary$adjr2[a0], col="red",cex=2,pch=20)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
b0=which.min(reg.summary$cp)
points(b0,reg.summary$cp[b0],col="red",cex=2,pch=20)
c0=which.min(reg.summary$bic)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(c0,reg.summary$bic[c0],col="red",cex=2,pch=20)
#Get the best model based on bic. coef(regfit.full,6) gives the best moddel with 6 predictors
coef(regfit.full,c0)
rm(list=ls())
library(data.table)
setwd("C:\\Users\\a-bibeka\\Documents\\GitHub\\Python-Code-Compilation")
dat<- fread("Q9Dat.csv")
fit<-aov(Y~factor(A)+factor(B)+factor(C)+factor(D)+factor(E)+factor(F)+factor(A):factor(C)+factor(A):factor(E),data=dat)
res=summary(fit)
fwrite(res,"anovaQ9.csv")
#***************************************************
#Subset Regression
dat<-fread("DesDatQ9.csv")
dat$V1=NULL
library(leaps)
#regsubsets is used for gettting a subset model that is best
Y=dat$Y
X=dat
X$Y=NULL
regfit.full=regsubsets(X,Y)
reg.summary=summary(regfit.full)
#
par(mfrow=c(2,2))
#Choosing RSS for best model for each p
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
#Choosing the adjusted R2 for best model for each p
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
#Value of p (predictor) for which the R2 is maximum
a0=which.max(reg.summary$adjr2)
points(a0,reg.summary$adjr2[a0], col="red",cex=2,pch=20)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
b0=which.min(reg.summary$cp)
points(b0,reg.summary$cp[b0],col="red",cex=2,pch=20)
c0=which.min(reg.summary$bic)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(c0,reg.summary$bic[c0],col="red",cex=2,pch=20)
#Get the best model based on bic. coef(regfit.full,6) gives the best moddel with 6 predictors
coef(regfit.full,c0)
View(dat)
rm(list=ls())
library(data.table)
setwd("C:\\Users\\a-bibeka\\Documents\\GitHub\\Python-Code-Compilation")
dat<- fread("Q9Dat.csv")
fit<-aov(Y~factor(A)+factor(B)+factor(C)+factor(D)+factor(E)+factor(F)+factor(A):factor(C)+factor(A):factor(E),data=dat)
res=summary(fit)
fwrite(res,"anovaQ9.csv")
#***************************************************
#Subset Regression
dat<-fread("DesDatQ9.csv")
dat$V1=NULL
library(leaps)
#regsubsets is used for gettting a subset model that is best
Y=dat$Y
X=dat
X$Y=NULL
regfit.full=regsubsets(X,Y)
reg.summary=summary(regfit.full)
#
par(mfrow=c(2,2))
#Choosing RSS for best model for each p
plot(reg.summary$rss,xlab="Number of Variables",ylab="RSS",type="l")
#Choosing the adjusted R2 for best model for each p
plot(reg.summary$adjr2,xlab="Number of Variables",ylab="Adjusted RSq",type="l")
#Value of p (predictor) for which the R2 is maximum
a0=which.max(reg.summary$adjr2)
points(a0,reg.summary$adjr2[a0], col="red",cex=2,pch=20)
plot(reg.summary$cp,xlab="Number of Variables",ylab="Cp",type='l')
b0=which.min(reg.summary$cp)
points(b0,reg.summary$cp[b0],col="red",cex=2,pch=20)
c0=which.min(reg.summary$bic)
plot(reg.summary$bic,xlab="Number of Variables",ylab="BIC",type='l')
points(c0,reg.summary$bic[c0],col="red",cex=2,pch=20)
#Get the best model based on bic. coef(regfit.full,6) gives the best moddel with 6 predictors
coef(regfit.full,c0)
