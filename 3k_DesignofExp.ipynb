{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct 11 20:08:07 2018\n",
    "@author: Apoorb\n",
    "#HW6 3**k Design of Experiment\n",
    "\"\"\"\n",
    "#Q3\n",
    "import os\n",
    "import pandas as pd\n",
    "from io import StringIO # Needed to read the data\n",
    "import math #To use math.log\n",
    "import numpy as np \n",
    "from scipy.stats import norm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model\n",
    "import statistics\n",
    "\n",
    "print('Current working directory ',os.getcwd())\n",
    "os.chdir('/Users/Apoorb/Documents/GitHub/Python-Code-Compilation')\n",
    "print('Current working directory ',os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to plot the Half-Normal Plot\n",
    "def HalfPlt_V1(DatTemp,Theta,Var_,PltName):\n",
    "    '''\n",
    "    DatTemp : Dataset with the effecs {\"FactEff\":[#,#,....],\"Var1\":[\"A\",\"B\"....]}\n",
    "    Theta : column name for effects; \"FactEff\"\n",
    "    Var_ : column name for list of variables; \"Var1\"\n",
    "    PltName : Name of the Half plot\n",
    "    '''\n",
    "    #Get the # of effects\n",
    "    len1 =len(DatTemp[Var_])\n",
    "    DatTemp['absTheta']=DatTemp[Theta].apply(abs)\n",
    "    DatTemp=DatTemp.sort_values(by=['absTheta'])\n",
    "    #Need to reset index after sort orderwise ploting will have error\n",
    "    DatTemp = DatTemp.reset_index(drop=True)\n",
    "    #Get the index of each sorted effect\n",
    "    DatTemp['i']= np.linspace(1,len1,len1).tolist()\n",
    "    DatTemp['NorQuant']=DatTemp['i'].apply(lambda x:norm.ppf(0.5+0.5*(x-0.5)/len1))\n",
    "    fig1, ax1 =plt.subplots()\n",
    "    ax1.scatter(DatTemp['NorQuant'], DatTemp['absTheta'], marker='x', color='red')\n",
    "    #Name all the points using Var1, enumerate gives index and value\n",
    "    for j,type in enumerate(DatTemp[Var_]):\n",
    "        x = DatTemp['NorQuant'][j]\n",
    "        y = DatTemp['absTheta'][j]\n",
    "        ax1.text(x+0.05, y+0.05, type, fontsize=9)\n",
    "    ax1.set_title(\"Half-Normal Plot\")\n",
    "    ax1.set_xlabel(\"Normal Quantile\")\n",
    "    ax1.set_ylabel(\"effects\")\n",
    "    fig1.savefig(PltName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform Lenth test\n",
    "#Lenth's Method for  testing signficance for experiments without\n",
    "# variance estimate\n",
    "def LenthsTest(dat,fef,fileNm,IER_Alpha=2.30):\n",
    "    '''\n",
    "    dat: Dataset with the effecs {\"FactEff\":[#,#,....],\"Var1\":[\"A\",\"B\"....]}\n",
    "    fef = column name for effects; \"FactEff\"\n",
    "    IER_Alpha = IER for n effects and alpha\n",
    "    '''\n",
    "    #Get the # of effects\n",
    "    len1=len(dat[fef])\n",
    "    dat['absEff']=dat[fef].apply(abs)\n",
    "    s0=1.5*statistics.median(map(float,dat['absEff']))\n",
    "    #Filter the effects\n",
    "    tpLst=[i for i in dat['absEff'] if i<2.5*s0]\n",
    "    #Get PSE \n",
    "    PSE =1.5 * statistics.median(tpLst)\n",
    "    #Lenth's t stat\n",
    "    dat['t_PSE'] = (round(dat[fef]/PSE,2))\n",
    "    dat['IER_Alpha']=[IER_Alpha]*len1\n",
    "    dat['Significant'] = dat.apply(lambda x : 'Significant' if abs(x['t_PSE']) > x['IER_Alpha'] else \"Not Significant\", axis=1)\n",
    "    dat.to_csv(fileNm)\n",
    "    return(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TempIO= StringIO('''Run A B C D S1 S2 S3 F1 F2 F3\n",
    "1 0 0 0 0 5164 6615 5959 12.89 12.70 12.74\n",
    "2 0 0 1 1 5356 6117 5224 12.83 12.73 13.07\n",
    "3 0 0 2 2 3070 3773 4257 12.37 12.47 12.44\n",
    "4 0 1 0 1 5547 6566 6320 13.29 12.86 12.70\n",
    "5 0 1 1 2 4754 4401 5436 12.64 12.50 12.61\n",
    "6 0 1 2 0 5524 4050 4526 12.76 12.72 12.94\n",
    "7 0 2 0 2 5684 6251 6214 13.17 13.33 13.98\n",
    "8 0 2 1 0 5735 6271 5843 13.02 13.11 12.67\n",
    "9 0 2 2 1 5744 4797 5416 12.37 12.67 12.54\n",
    "10 1 0 0 1 6843 6895 6957 13.28 13.65 13.58\n",
    "11 1 0 1 2 6538 6328 4784 12.62 14.07 13.38\n",
    "12 1 0 2 0 6152 5819 5963 13.19 12.94 13.15\n",
    "13 1 1 0 2 6854 6804 6907 14.65 14.98 14.40\n",
    "14 1 1 1 0 6799 6703 6792 13.00 13.35 12.87\n",
    "15 1 1 2 1 6513 6503 6568 13.13 13.40 13.80\n",
    "16 1 2 0 0 6473 6974 6712 13.55 14.10 14.41\n",
    "17 1 2 1 1 6832 7034 5057 14.86 13.27 13.64\n",
    "18 1 2 2 2 4968 5684 5761 13.00 13.58 13.45\n",
    "19 2 0 0 2 7148 6920 6220 16.70 15.85 14.90\n",
    "20 2 0 1 0 6905 7068 7156 14.70 13.97 13.66\n",
    "21 2 0 2 1 6933 7194 6667 13.51 13.64 13.92\n",
    "22 2 1 0 0 7227 7170 7015 15.54 16.16 16.14\n",
    "23 2 1 1 1 7014 7040 7200 13.97 14.09 14.52\n",
    "24 2 1 2 2 6215 6260 6488 14.35 13.56 13.00\n",
    "25 2 2 0 1 7145 6868 6964 15.70 16.45 15.85\n",
    "26 2 2 1 2 7161 7263 6937 15.21 13.77 14.34\n",
    "27 2 2 2 0 7060 7050 6950 13.51 13.42 13.07\n",
    "''')\n",
    "Df=pd.read_csv(TempIO,delimiter=r\"\\s+\",header=0)\n",
    "Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df['S_lnsBar']= Df[['S1','S2','S3']].apply(statistics.variance,axis=1).apply(math.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df['F_lnsBar']=((Df[['F1','F2','F3']].std(axis=1))**2).apply(math.log)\n",
    "Df=Df.drop([\"D\",\"S1\",\"S2\",\"S3\",\"F1\",\"F2\",\"F3\"],axis=1)\n",
    "Zs=np.matrix(Df.S_lnsBar)\n",
    "Df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def contrast_l(ef):\n",
    "    contr=int()\n",
    "    if(ef==0):contr=-1/math.sqrt(2)\n",
    "    elif(ef==1):contr=0/math.sqrt(2)\n",
    "    else:contr=1/math.sqrt(2)\n",
    "    return contr\n",
    "def contrast_q(ef):\n",
    "    contr=int()\n",
    "    if(ef==0):contr=1/math.sqrt(6)\n",
    "    elif(ef==1):contr=-2/math.sqrt(6)\n",
    "    else:contr=1/math.sqrt(6)\n",
    "    return contr\n",
    "'''\n",
    "def contrast_l(ef):\n",
    "    contr=int()\n",
    "    if(ef==0):contr=-1\n",
    "    elif(ef==1):contr=0\n",
    "    else:contr=1\n",
    "    return contr\n",
    "def contrast_q(ef):\n",
    "    contr=int()\n",
    "    if(ef==0):contr=1\n",
    "    elif(ef==1):contr=-2\n",
    "    else:contr=1\n",
    "    return contr\n",
    "'''\n",
    "# 6 Main effects\n",
    "Df[\"Al\"]=Df.A.apply(contrast_l)\n",
    "Df[\"Bl\"]=Df.B.apply(contrast_l)\n",
    "Df[\"Cl\"]=Df.C.apply(contrast_l)\n",
    "Df[\"Aq\"]=Df.A.apply(contrast_q)\n",
    "Df[\"Bq\"]=Df.B.apply(contrast_q)\n",
    "Df[\"Cq\"]=Df.C.apply(contrast_q)\n",
    "\n",
    "# 12 2 way effects\n",
    "Df[\"ABll\"]=Df.loc[:,[\"Al\",\"Bl\"]].apply(np.product,axis=1)\n",
    "Df[\"ABlq\"]=Df.loc[:,[\"Al\",\"Bq\"]].apply(np.product,axis=1)\n",
    "Df[\"ABql\"]=Df.loc[:,[\"Aq\",\"Bl\"]].apply(np.product,axis=1)\n",
    "Df[\"ABqq\"]=Df.loc[:,[\"Aq\",\"Bq\"]].apply(np.product,axis=1)\n",
    "\n",
    "Df[\"ACll\"]=Df.loc[:,[\"Al\",\"Cl\"]].apply(np.product,axis=1)\n",
    "Df[\"AClq\"]=Df.loc[:,[\"Al\",\"Cq\"]].apply(np.product,axis=1)\n",
    "Df[\"ACql\"]=Df.loc[:,[\"Aq\",\"Cl\"]].apply(np.product,axis=1)\n",
    "Df[\"ACqq\"]=Df.loc[:,[\"Aq\",\"Cq\"]].apply(np.product,axis=1)\n",
    "\n",
    "Df[\"BCll\"]=Df.loc[:,[\"Bl\",\"Cl\"]].apply(np.product,axis=1)\n",
    "Df[\"BClq\"]=Df.loc[:,[\"Bl\",\"Cq\"]].apply(np.product,axis=1)\n",
    "Df[\"BCql\"]=Df.loc[:,[\"Bq\",\"Cl\"]].apply(np.product,axis=1)\n",
    "Df[\"BCqq\"]=Df.loc[:,[\"Bq\",\"Cq\"]].apply(np.product,axis=1)\n",
    "\n",
    "# 8 3 way effects\n",
    "Df[\"ABClll\"]=Df.loc[:,[\"Al\",\"Bl\",\"Cl\"]].apply(np.product,axis=1)\n",
    "Df[\"ABCllq\"]=Df.loc[:,[\"Al\",\"Bl\",\"Cq\"]].apply(np.product,axis=1)\n",
    "Df[\"ABClql\"]=Df.loc[:,[\"Al\",\"Bq\",\"Cl\"]].apply(np.product,axis=1)\n",
    "Df[\"ABCqll\"]=Df.loc[:,[\"Aq\",\"Bl\",\"Cl\"]].apply(np.product,axis=1)\n",
    "Df[\"ABClqq\"]=Df.loc[:,[\"Al\",\"Bq\",\"Cq\"]].apply(np.product,axis=1)\n",
    "Df[\"ABCqql\"]=Df.loc[:,[\"Aq\",\"Bq\",\"Cl\"]].apply(np.product,axis=1)\n",
    "Df[\"ABCqlq\"]=Df.loc[:,[\"Aq\",\"Bl\",\"Cq\"]].apply(np.product,axis=1)\n",
    "Df[\"ABCqqq\"]=Df.loc[:,[\"Aq\",\"Bq\",\"Cq\"]].apply(np.product,axis=1)\n",
    "Df.to_csv(\"Data_Str.csv\")\n",
    "Df.iloc[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Df.iloc[:,6:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Df.columns\n",
    "Df.loc[:,[\"Al\",\"S_lnsBar\"]].apply(np.product,axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Df.iloc[:,6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=np.matrix(X)\n",
    "Diag=(X1.transpose()*X1).diagonal()\n",
    "Diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef2=(Zs*X1).tolist()[0]\n",
    "dat=pd.DataFrame({\"FactEff_t\":ef2,\"Var1\":X.columns})\n",
    "ef2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.divide((Zs*X1),Diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr=linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "Zs1=Df.S_lnsBar\n",
    "R1=regr.fit(X,Zs1)\n",
    "R1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ef2=R1.coef_\n",
    "ef2\n",
    "dat=pd.DataFrame({\"FactEff\":ef2,\"Var1\":X.columns})\n",
    "#dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HalfPlt_V1(dat,'FactEff','Var1','HalfPlotStrn.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
